{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t4iDMXDXCiXL"
   },
   "source": [
    "# Agents:\n",
    "These simulations evaluate several agents exploring the thread the needle enviroment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gX_WcaJrCiXO"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# from IPython.display import display, HTML\n",
    "# display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27310,
     "status": "ok",
     "timestamp": 1695324330501,
     "user": {
      "displayName": "Nicholas Franklin",
      "userId": "12504197633357716328"
     },
     "user_tz": 240
    },
    "id": "rs6RRdxzCiXP",
    "outputId": "eca04536-735a-413c-b345-20ea4c466826"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python 3.10.13 (main, Sep 11 2023, 08:16:02) [Clang 14.0.6 ]\n",
      "torch 2.2.1\n",
      "device = mps\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "import networkx as nx\n",
    "\n",
    "from model.training.rollout_data import PriorityReplayBuffer as Buffer\n",
    "from task.gridworld import CnnWrapper, ThreadTheNeedleEnv\n",
    "from utils.config_utils import parse_task_config, parse_model_config, load_config\n",
    "from utils.pytorch_utils import DEVICE\n",
    "from model.agents.discrete_ppo import DiscretePPO\n",
    "\n",
    "from utils.pytorch_utils import (\n",
    "    convert_float_to_8bit\n",
    ")\n",
    "\n",
    "print(f\"python {sys.version}\")\n",
    "print(f\"torch {torch.__version__}\")\n",
    "print(f\"device = {DEVICE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 140,
     "referenced_widgets": [
      "35db648b0ccf49a898f46c7002c182ff",
      "1652455236434fd595f478f228333ade",
      "971b821eb13d4257a7c2ae73381df11e",
      "b44689589e2b4f1dbb45f61c49d4062f",
      "60ad1b1ffe8c47518fb905de5a2ba43b",
      "d1d32540b92e4e4584ac3aa628436021",
      "ce22fd1425e34878b5bf57a180e6b68a",
      "532462010a464a408a44e376dbbd6ec2",
      "f15532d5a2d84f078b135130546e00f9",
      "a8b47418ba51421396006975690322d2",
      "3a6976f1e97e4bfa9c820ae22c022177",
      "15f65c7bfcf8405c918f61372c86fc6e"
     ]
    },
    "executionInfo": {
     "elapsed": 9290,
     "status": "ok",
     "timestamp": 1695324339781,
     "user": {
      "displayName": "Nicholas Franklin",
      "userId": "12504197633357716328"
     },
     "user_tz": 240
    },
    "id": "zMjOepyHCiXQ",
    "outputId": "a392baec-a650-473f-cbf0-bc83702b2099"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d882d6c7d46b4c76874440eaa77fe22c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CONFIG_PATH = \"configs\"\n",
    "TASK_CONFIG_FILE = \"env_config.yml\"\n",
    "VAE_CONFIG_FILE = \"vae_config.yml\"\n",
    "AGENT_CONFIG_FILE = \"discrete_ppo_config.yml\"\n",
    "\n",
    "TASK_NAME = \"thread_the_needle\"\n",
    "MODEL_NAME = \"cnn_vae\"\n",
    "\n",
    "# Create log dir\n",
    "LOG_DIR = \"tmp/\"\n",
    "os.makedirs(LOG_DIR, exist_ok=True)\n",
    "\n",
    "TASK_CLASS = ThreadTheNeedleEnv\n",
    "AgentClass = DiscretePPO\n",
    "\n",
    "## Load Configs\n",
    "task_config_file = os.path.join(CONFIG_PATH, TASK_CONFIG_FILE)\n",
    "vae_config_file = os.path.join(CONFIG_PATH, VAE_CONFIG_FILE)\n",
    "agent_config_file = os.path.join(CONFIG_PATH, AGENT_CONFIG_FILE)\n",
    "\n",
    "env_kwargs = parse_task_config(TASK_NAME, task_config_file)\n",
    "vae_config = parse_model_config(MODEL_NAME, vae_config_file)\n",
    "agent_config = load_config(agent_config_file)\n",
    "\n",
    "# create the task and get the optimal policy\n",
    "task = CnnWrapper(TASK_CLASS.create_env(**env_kwargs))\n",
    "pi, _ = task.get_optimal_policy()\n",
    "\n",
    "SAVE_FILE_NAME = f\"simulations/thread_the_needle_viagent_offline.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "a97baba4f7ad45d68e6642ec5a2c0661"
     ]
    },
    "id": "pDEaG39L87kE",
    "outputId": "e9294926-8a92-4d41-af1c-e012f0948270"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasfranklin/miniconda3/envs/state_inference/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.get_optimal_policy to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.get_optimal_policy` for environment variables or `env.get_wrapper_attr('get_optimal_policy')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "422da3f1acd7426c9b7022ae9fb6e2d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create the task and get the optimal policy\n",
    "task = TASK_CLASS.create_env(**env_kwargs)\n",
    "task = CnnWrapper(task)\n",
    "\n",
    "# create the monitor\n",
    "task = Monitor(task, LOG_DIR)\n",
    "\n",
    "pi, _ = task.get_optimal_policy()\n",
    "# training_kwargs[\"optimal_policy\"] = pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dir(task.action_space)\n",
    "task.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args: ['env', 'state_inference_model']\n",
      "Kwargs: ['gamma', 'lr', 'n_steps', 'clip', 'grad_clip', 'optim_kwargs', 'n_epochs', 'batch_size', 'epsilon']\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "\n",
    "# Get the signature of the __init__ method of DiscretePPO\n",
    "sig = inspect.signature(DiscretePPO.__init__)\n",
    "\n",
    "# Iterate through the parameters to separate args and kwargs\n",
    "args = []\n",
    "kwargs = []\n",
    "for param in sig.parameters.values():\n",
    "    # Skip 'self' parameter for methods\n",
    "    if param.name == 'self':\n",
    "        continue\n",
    "    if param.default == inspect.Parameter.empty:\n",
    "        args.append(param.name)\n",
    "    else:\n",
    "        kwargs.append(param.name)\n",
    "\n",
    "print(\"Args:\", args)\n",
    "print(\"Kwargs:\", kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vae_model_class': 'StateVae',\n",
       " 'n_train_steps': 30000,\n",
       " 'n_batches': 12,\n",
       " 'value_iteration_kwargs': {'gamma': 0.9,\n",
       "  'n_iter': 1000,\n",
       "  'softmax_gain': 1.0,\n",
       "  'epsilon': 0.05,\n",
       "  'batch_length': 'None'},\n",
       " 'state_inference_model': {'batch_size': 64,\n",
       "  'n_epochs': 10,\n",
       "  'grad_clip': 1.0,\n",
       "  'n_steps': 2048,\n",
       "  'persistant_optim': True}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 397,
     "status": "ok",
     "timestamp": 1695324340489,
     "user": {
      "displayName": "Nicholas Franklin",
      "userId": "12504197633357716328"
     },
     "user_tz": 240
    },
    "id": "3ICAzJwrCiXR",
    "outputId": "9840cbf2-a1c2-4a79-cf2b-05d36b62436e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 1970545\n"
     ]
    }
   ],
   "source": [
    "### Model + Training Parameters\n",
    "\n",
    "vae_config = parse_model_config(MODEL_NAME, vae_config_file)\n",
    "agent_config = load_config(agent_config_file)\n",
    "\n",
    "\n",
    "def make_model():\n",
    "    agent = AgentClass.make_from_configs(task, agent_config, vae_config, env_kwargs)\n",
    "    agent = agent.to(DEVICE)\n",
    "    return agent\n",
    "\n",
    "agent = make_model()\n",
    "total_params = sum(p.numel() for p in agent.state_inference_model.parameters())\n",
    "print(f\"Number of parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdamW (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    capturable: False\n",
       "    differentiable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    lr: 0.0003\n",
       "    maximize: False\n",
       "    weight_decay: 0.01\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7qmmETd4CiXR",
    "outputId": "30368cd4-7362-4888-a8bf-de0f3819fc1b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b48442f90f754f54bc5ade663084dfcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent = make_model()\n",
    "\n",
    "# agent.learn(total_timesteps=10000, progress_bar=True) # previous model\n",
    "agent.learn(total_timesteps=2048, progress_bar=True)\n",
    "# agent.learn(total_timesteps=1000, progress_bar=True, capacity=750)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DiscretePPO(\n",
       "  (state_inference_model): StateVae(\n",
       "    (encoder): CnnEncoder(\n",
       "      (cnn): Sequential(\n",
       "        (0): ConvBlock(\n",
       "          (conv): Conv2d(1, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (act): ELU(alpha=1.0)\n",
       "        )\n",
       "        (1): ConvBlock(\n",
       "          (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (act): ELU(alpha=1.0)\n",
       "        )\n",
       "        (2): ConvBlock(\n",
       "          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (act): ELU(alpha=1.0)\n",
       "        )\n",
       "        (3): ConvBlock(\n",
       "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (act): ELU(alpha=1.0)\n",
       "        )\n",
       "        (4): ConvBlock(\n",
       "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (act): ELU(alpha=1.0)\n",
       "        )\n",
       "      )\n",
       "      (mlp): Sequential(\n",
       "        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (2): ELU(alpha=1.0)\n",
       "        (3): Linear(in_features=1024, out_features=64, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (decoder): CnnDecoder(\n",
       "      (fc): Linear(in_features=64, out_features=1024, bias=True)\n",
       "      (deconv): Sequential(\n",
       "        (0): ConvTransposeBlock(\n",
       "          (conv_t): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "          (act): ELU(alpha=1.0)\n",
       "        )\n",
       "        (1): ConvTransposeBlock(\n",
       "          (conv_t): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "          (act): ELU(alpha=1.0)\n",
       "        )\n",
       "        (2): ConvTransposeBlock(\n",
       "          (conv_t): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "          (act): ELU(alpha=1.0)\n",
       "        )\n",
       "        (3): ConvTransposeBlock(\n",
       "          (conv_t): ConvTranspose2d(32, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "          (act): ELU(alpha=1.0)\n",
       "        )\n",
       "      )\n",
       "      (final_layer): Sequential(\n",
       "        (0): ConvTranspose2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): GELU(approximate='none')\n",
       "        (3): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (actor_net): MLP(\n",
       "    (net): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ELU(alpha=1.0)\n",
       "      (3): Linear(in_features=64, out_features=4, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (critic): MLP(\n",
       "    (net): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ELU(alpha=1.0)\n",
       "      (3): Linear(in_features=64, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collection rollouts:   0%|                                                                                                          | 0/10000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected more than 1 value per channel when training, got input size torch.Size([1, 64])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m rollouts \u001b[38;5;241m=\u001b[39m Buffer()\n\u001b[0;32m----> 2\u001b[0m rollouts \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_buffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrollouts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.05\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/StateInference/model/agents/utils/base_agent.py:258\u001b[0m, in \u001b[0;36mBaseAgent.collect_buffer\u001b[0;34m(self, task, buffer, n, epsilon, start_state)\u001b[0m\n\u001b[1;32m    255\u001b[0m done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(n), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCollection rollouts\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 258\u001b[0m     action_pmf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_pmf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m# epsilon greedy\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     action_pmf \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m epsilon) \u001b[38;5;241m*\u001b[39m action_pmf \u001b[38;5;241m+\u001b[39m epsilon \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mones_like(\n\u001b[1;32m    262\u001b[0m         action_pmf\n\u001b[1;32m    263\u001b[0m     ) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(action_pmf)\n",
      "File \u001b[0;32m~/miniconda3/envs/state_inference/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/StateInference/model/agents/discrete_ppo.py:147\u001b[0m, in \u001b[0;36mDiscretePPO.get_pmf\u001b[0;34m(self, obs)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39mno_grad()\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_pmf\u001b[39m(\u001b[38;5;28mself\u001b[39m, obs: FloatTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m    145\u001b[0m     (logits, z), _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed(obs)\n\u001b[0;32m--> 147\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m     dist \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdistributions\u001b[38;5;241m.\u001b[39mCategorical(logits\u001b[38;5;241m=\u001b[39mlogits)\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dist\u001b[38;5;241m.\u001b[39mprobs\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/Projects/StateInference/model/agents/discrete_ppo.py:155\u001b[0m, in \u001b[0;36mDiscretePPO.actor\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mactor\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: FloatTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m FloatTensor:\n\u001b[1;32m    153\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"we use e-softmax policy here, mostly for numerical stability during training\"\"\"\u001b[39;00m\n\u001b[0;32m--> 155\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactor_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;66;03m# Step 1: Normalize the logits using log-softmax\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     log_normalized_probs \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mlog_softmax(logits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/state_inference/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/state_inference/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/StateInference/model/state_inference/nets/mlp.py:39\u001b[0m, in \u001b[0;36mMLP.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/state_inference/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/state_inference/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/state_inference/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/state_inference/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/state_inference/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/state_inference/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:175\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    168\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    170\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/state_inference/lib/python3.10/site-packages/torch/nn/functional.py:2480\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2467\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m   2468\u001b[0m         batch_norm,\n\u001b[1;32m   2469\u001b[0m         (\u001b[38;5;28minput\u001b[39m, running_mean, running_var, weight, bias),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2477\u001b[0m         eps\u001b[38;5;241m=\u001b[39meps,\n\u001b[1;32m   2478\u001b[0m     )\n\u001b[1;32m   2479\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[0;32m-> 2480\u001b[0m     \u001b[43m_verify_batch_size\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2482\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mbatch_norm(\n\u001b[1;32m   2483\u001b[0m     \u001b[38;5;28minput\u001b[39m, weight, bias, running_mean, running_var, training, momentum, eps, torch\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mcudnn\u001b[38;5;241m.\u001b[39menabled\n\u001b[1;32m   2484\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/state_inference/lib/python3.10/site-packages/torch/nn/functional.py:2448\u001b[0m, in \u001b[0;36m_verify_batch_size\u001b[0;34m(size)\u001b[0m\n\u001b[1;32m   2446\u001b[0m     size_prods \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m size[i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m   2447\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_prods \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m-> 2448\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected more than 1 value per channel when training, got input size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Expected more than 1 value per channel when training, got input size torch.Size([1, 64])"
     ]
    }
   ],
   "source": [
    "rollouts = Buffer()\n",
    "rollouts = agent.collect_buffer(task, rollouts, 10000, epsilon=0.05)\n",
    "# rollouts = agent.collect_buffer(task, rollouts, 2000, epsilon=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argwhere(rollouts.get_dataset()['rewards'] > 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Laplacian, state_key = agent.get_graph_laplacian(rollouts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Laplacian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the laplacian into a graph\n",
    "edges = np.argwhere(Laplacian)\n",
    "edges = [(i, j) for i, j in edges if i != j]  # remove self-edges\n",
    "\n",
    "G = nx.Graph()\n",
    "G.add_edges_from(edges)\n",
    "nx.draw_networkx(G, with_labels=False, node_size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent.get_state_values(state_key)\n",
    "node_values = {state_key.get(i, -1): v for i, v in agent.get_state_values(state_key).items()}\n",
    "# node_values.pop(-1)\n",
    "\n",
    "# normalize the node_values\n",
    "v_max = max([v for v in node_values.values()])\n",
    "v_min = min([v for v in node_values.values()])\n",
    "f = lambda v: (v - v_min) / (v_max - v_min)\n",
    "node_values = {k: f(v) for k, v in node_values.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the laplacian into a graph\n",
    "edges = np.argwhere(Laplacian)\n",
    "edges = [(i, j) for i, j in edges if i != j]  # remove self-edges\n",
    "\n",
    "G = nx.Graph()\n",
    "G.add_edges_from(edges)\n",
    "\n",
    "color = [node_values.get(i, 0) for i in G.nodes]\n",
    "size = [node_values.get(i, 0) * 25 for i in G.nodes]\n",
    "nx.draw_networkx(G, with_labels=False, node_size=size, node_color=color, cmap=\"viridis\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(state_key), print(node_values)\n",
    "\n",
    "obs = None\n",
    "for hashed_state, node in state_key.items():\n",
    "    v = node_values.get(node, 0)\n",
    "\n",
    "    z = agent.dehash_states(hashed_state)\n",
    "    obs_ = agent.state_inference_model.decode(agent.collocate(z))\n",
    "    if obs is None:\n",
    "        obs = v * obs_\n",
    "    else:\n",
    "        obs += v * obs_\n",
    "plt.imshow(obs.squeeze().cpu().detach().numpy())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_model = agent.state_inference_model\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Sample generatively\n",
    "\n",
    "z_layers = vae_config[\"vae_kwargs\"][\"z_layers\"]\n",
    "z_dim = vae_config[\"vae_kwargs\"][\"z_dim\"]\n",
    "\n",
    "N = 4\n",
    "\n",
    "\n",
    "def sample_random_state():\n",
    "    z = torch.randint(high=z_dim, size=tuple([z_layers]))\n",
    "    return F.one_hot(z, num_classes=z_dim).to(DEVICE)\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(N, N, figsize=(9, 9))\n",
    "\n",
    "vae_model.eval()\n",
    "for t in range(N**2):\n",
    "    with torch.no_grad():\n",
    "        z = sample_random_state()\n",
    "    X_hat = vae_model.decode(z).detach().cpu()\n",
    "\n",
    "    r, c = t // N, t % N\n",
    "    plt.sca(axes[r][c])\n",
    "    plt.imshow(convert_float_to_8bit(X_hat.squeeze()))\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_DoORPwACiXS"
   },
   "outputs": [],
   "source": [
    "\n",
    "pmf = agent.get_policy_prob(agent.get_env(), n_states=env_kwargs[\"n_states\"], map_height=env_kwargs[\"map_height\"], cnn=True)\n",
    "pmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A9ZN0N0v87kF"
   },
   "outputs": [],
   "source": [
    "sorted(list(agent.value_function.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fXiMheY5CiXS"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "fig, axes = plt.subplots(2, 2)\n",
    "h, w = env_kwargs[\"height\"], env_kwargs[\"width\"]\n",
    "\n",
    "axes[0][0].imshow(pmf[:, 0].reshape(h, w))\n",
    "axes[0][1].imshow(pmf[:, 1].reshape(h, w))\n",
    "axes[1][0].imshow(pmf[:, 2].reshape(h, w))\n",
    "axes[1][1].imshow(pmf[:, 3].reshape(h, w))\n",
    "\n",
    "\n",
    "axes[0][0].set_title(\"up\")\n",
    "axes[0][1].set_title(\"down\")\n",
    "axes[1][0].set_title(\"left\")\n",
    "axes[1][1].set_title(\"right\")\n",
    "\n",
    "plt.subplots_adjust(hspace=0.3, wspace=-0.3)\n",
    "\n",
    "plt.suptitle(\"Value Iteration Agent Learned Policy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IOdHTncFCiXS"
   },
   "outputs": [],
   "source": [
    "np.sum(pi * pmf, axis=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tDWbaK8TCiXS"
   },
   "outputs": [],
   "source": [
    "room_1_mask = (np.arange(400) < 200) * (np.arange(400) % 20 < 10)\n",
    "room_2_mask = (np.arange(400) >= 200) * (np.arange(400) % 20 < 10)\n",
    "room_3_mask = np.arange(400) % 20 >= 10\n",
    "\n",
    "score_room_1 = np.sum(pi[room_1_mask] * pmf[room_1_mask], axis=1).mean()\n",
    "score_room_2 = np.sum(pi[room_2_mask] * pmf[room_2_mask], axis=1).mean()\n",
    "score_room_3 = np.sum(pi[room_3_mask] * pmf[room_3_mask], axis=1).mean()\n",
    "plt.bar([0, 1, 2], [score_room_1, score_room_2, score_room_3])\n",
    "\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0VGwADB2CiXS"
   },
   "outputs": [],
   "source": [
    "from utils.pytorch_utils import make_tensor, convert_8bit_to_float\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "obs = convert_8bit_to_float(\n",
    "    torch.stack(\n",
    "        [\n",
    "            make_tensor(task.observation_model(s))\n",
    "            for s in range(task.transition_model.n_states)\n",
    "            for _ in range(1)\n",
    "        ]\n",
    "    )\n",
    ")[:, None, ...].to(DEVICE)\n",
    "z = agent.state_inference_model.get_state(obs)\n",
    "\n",
    "hash_vector = np.array(\n",
    "    [\n",
    "        agent.state_inference_model.z_dim**ii\n",
    "        for ii in range(agent.state_inference_model.z_layers)\n",
    "    ]\n",
    ")\n",
    "\n",
    "z = z.dot(hash_vector)\n",
    "d = pairwise_distances(z.reshape(-1, 1), metric=lambda x, y: x == y)\n",
    "plt.imshow(1 - d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "37Utcb05CiXT"
   },
   "outputs": [],
   "source": [
    "# plot the overlap of different states\n",
    "# number the states and plot them\n",
    "clusters = {}\n",
    "k = 0\n",
    "for z0 in sorted(z):\n",
    "    if z0 not in clusters.keys():\n",
    "        clusters[z0] = k\n",
    "        k += 1\n",
    "clustered_states = np.array([clusters[z0] for z0 in z])\n",
    "plt.imshow(clustered_states.reshape(-1, 20))\n",
    "task.display_gridworld(plt.gca(), wall_color=\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0fPoGEdJCiXT"
   },
   "outputs": [],
   "source": [
    "euc = pairwise_distances(\n",
    "    [(x, y) for x in range(20) for y in range(20)],\n",
    "    # metric=lambda x, y: np.sqrt((x[0] - y[0]) ** 2 + (x[1] - y[1]) ** 2),\n",
    "    metric=lambda x, y: np.abs(x[0] - y[0]) + np.abs(x[1] - y[1]),\n",
    ")\n",
    "\n",
    "d_w_wall = np.mean([d[s1][s2] for s1, s2 in task.transition_model.walls])\n",
    "print(f\"Distance between neighboring states sepearted by a wall     {d_w_wall}\")\n",
    "\n",
    "\n",
    "wall_mask = np.zeros((task.n_states, task.n_states))\n",
    "for s0, s1 in task.transition_model.walls:\n",
    "    wall_mask[s0][s1] = 1.0\n",
    "    wall_mask[s1][s0] = 1.0\n",
    "\n",
    "\n",
    "d_wo_wall = d.reshape(-1)[(wall_mask.reshape(-1) == 0) & (euc.reshape(-1) == 1)].mean()\n",
    "print(f\"Distance between neighboring states NOT sepearted by a wall {d_wo_wall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nGaOqXE9CiXT"
   },
   "outputs": [],
   "source": [
    "# agent._estimate_reward_model()\n",
    "\n",
    "rews = np.array([agent.reward_estimator.get_avg_reward(z0) for z0 in z]).reshape(20, 20)\n",
    "plt.imshow(rews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vet80FEzCiXT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VuuFGzi2CiXT"
   },
   "outputs": [],
   "source": [
    "obs = convert_8bit_to_float(\n",
    "    torch.stack(\n",
    "        [\n",
    "            make_tensor(task.observation_model(s))\n",
    "            for s in range(task.transition_model.n_states)\n",
    "            for _ in range(1)\n",
    "        ]\n",
    "    )\n",
    ")[:, None, ...].to(DEVICE)\n",
    "z = agent.state_inference_model.get_state(obs)\n",
    "\n",
    "hash_vector = np.array(\n",
    "    [\n",
    "        agent.state_inference_model.z_dim**ii\n",
    "        for ii in range(agent.state_inference_model.z_layers)\n",
    "    ]\n",
    ")\n",
    "\n",
    "z = z.dot(hash_vector)\n",
    "\n",
    "rews = np.array([agent.reward_estimator.get_avg_reward(z0) for z0 in z]).reshape(20, 20)\n",
    "plt.imshow(rews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WQ8VNDjACiXT"
   },
   "outputs": [],
   "source": [
    "def get_value_function(model, task):\n",
    "    obs = convert_8bit_to_float(\n",
    "        torch.stack(\n",
    "            [\n",
    "                make_tensor(task.observation_model(s))\n",
    "                for s in range(task.transition_model.n_states)\n",
    "                for _ in range(1)\n",
    "            ]\n",
    "        )\n",
    "    )[:, None, ...].to(DEVICE)\n",
    "    z = model.state_inference_model.get_state(obs)\n",
    "\n",
    "    hash_vector = np.array(\n",
    "        [\n",
    "            model.state_inference_model.z_dim**ii\n",
    "            for ii in range(agent.state_inference_model.z_layers)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    z = z.dot(hash_vector)\n",
    "\n",
    "    value_function = np.array(\n",
    "        [agent.value_function.get(z0, np.nan) for z0 in z]\n",
    "    ).reshape(20, 20)\n",
    "    return value_function\n",
    "\n",
    "\n",
    "v = get_value_function(agent, task)\n",
    "plt.imshow(v)\n",
    "task.display_gridworld(plt.gca(), wall_color=\"w\", annotate=True)\n",
    "plt.title(\"Learned Value function\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "miK3Yk9SCiXU"
   },
   "outputs": [],
   "source": [
    "plt.plot(v[5] - np.nanmin(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise Exception(\"Stop here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UuVki8C5CiXU"
   },
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "\n",
    "\n",
    "## Repeat with iterations\n",
    "n_models = 8\n",
    "# n_models=4\n",
    "\n",
    "\n",
    "room_1_mask = (np.arange(400) < 200) * (np.arange(400) % 20 < 10)\n",
    "room_2_mask = (np.arange(400) >= 200) * (np.arange(400) % 20 < 10)\n",
    "room_3_mask = np.arange(400) % 20 >= 10\n",
    "\n",
    "\n",
    "scores = []\n",
    "value_functions = []\n",
    "\n",
    "\n",
    "for idx in trange(n_models):\n",
    "    agent = make_model()\n",
    "    agent.learn(total_timesteps=agent_config[\"n_train_steps\"], progress_bar=False)\n",
    "    #     agent.learn(total_timesteps=500, progress_bar=False)\n",
    "\n",
    "    pmf = get_policy_prob(\n",
    "        agent,\n",
    "        vae_get_pmf,\n",
    "        n_states=env_kwargs[\"n_states\"],\n",
    "        map_height=env_kwargs[\"map_height\"],\n",
    "        cnn=True,\n",
    "    )\n",
    "\n",
    "    score_room_1 = np.sum(pi[room_1_mask] * pmf[room_1_mask], axis=1).mean()\n",
    "    score_room_2 = np.sum(pi[room_2_mask] * pmf[room_2_mask], axis=1).mean()\n",
    "    score_room_3 = np.sum(pi[room_3_mask] * pmf[room_3_mask], axis=1).mean()\n",
    "\n",
    "    v = get_value_function(agent, task)\n",
    "\n",
    "    scores.append(\n",
    "        pd.DataFrame(\n",
    "            {\n",
    "                \"Iteration\": [idx] * 4,\n",
    "                \"Score\": [\n",
    "                    np.sum(pi * pmf, axis=1).mean(),\n",
    "                    score_room_1,\n",
    "                    score_room_2,\n",
    "                    score_room_3,\n",
    "                ],\n",
    "                \"Condition\": [\"Overall\", \"Room 1\", \"Room 2\", \"Room 3\"],\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "\n",
    "    value_functions.append(\n",
    "        pd.DataFrame(\n",
    "            {\n",
    "                \"Iteration\": [idx] * task.n_states,\n",
    "                \"State-Values\": v.reshape(-1),\n",
    "                \"States\": np.arange(task.n_states),\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "\n",
    "scores = pd.concat(scores)\n",
    "value_functions = pd.concat(value_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NY0NZDioCiXU"
   },
   "outputs": [],
   "source": [
    "# Plot the average value function (n)\n",
    "\n",
    "# normalize the value function between zero and one within each iteration\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "def min_max_scale(grouped_data):\n",
    "    v = grouped_data[\"State-Values\"].values.reshape(-1, 1)\n",
    "    v = MinMaxScaler().fit_transform(grouped_data[\"State-Values\"].values.reshape(-1, 1))\n",
    "    grouped_data[\"State-Values\"] = v\n",
    "    return grouped_data.drop(\"Iteration\", axis=1)\n",
    "\n",
    "\n",
    "normed_vf = value_functions.groupby(\"Iteration\", group_keys=True).apply(min_max_scale)\n",
    "\n",
    "# average and plot\n",
    "plt.imshow(x.groupby(\"States\").mean().values.reshape(20, 20))\n",
    "task.display_gridworld(plt.gca(), wall_color=\"w\", annotate=True)\n",
    "plt.title(\"Learned Value function\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wj_z0BzYCiXU"
   },
   "outputs": [],
   "source": [
    "# plot 1d Value function through the goal\n",
    "normed_vf[\"Row\"] = normed_vf[\"States\"] // 20\n",
    "normed_vf[\"Column\"] = normed_vf[\"States\"] % 20\n",
    "\n",
    "sns.relplot(\n",
    "    data=normed_vf[normed_vf[\"Row\"] == 4], x=\"Column\", y=\"State-Values\", kind=\"line\"\n",
    ")\n",
    "sns.relplot(\n",
    "    data=normed_vf[(normed_vf[\"Column\"] >= 9) & (normed_vf[\"Column\"] <= 10)],\n",
    "    x=\"Row\",\n",
    "    y=\"State-Values\",\n",
    "    kind=\"line\",\n",
    "    hue=\"Column\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nLzKl0_kCiXU"
   },
   "source": [
    "plt.imshow(\n",
    "    value_functions.groupby(\"States\")[\"State-Values\"]\n",
    "    .apply(np.nanmean)\n",
    "    .values.reshape(20, 20)\n",
    ")\n",
    "value_functions.to_csv('value_functions_vae.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FPepkS2fCiXU"
   },
   "outputs": [],
   "source": [
    "sns.catplot(data=scores, y=\"Score\", x=\"Condition\", kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hp9hNe3UCiXU"
   },
   "outputs": [],
   "source": [
    "scores[\"Model\"] = \"Value Iteration\"\n",
    "scores.to_csv(SAVE_FILE_NAME)\n",
    "scores2 = pd.read_csv(\"sims_thread_the_needle.csv\")\n",
    "scores2[\"Model\"] = \"PPO\"\n",
    "scores3 = pd.read_csv(\"sims_thread_the_needle_state_inf.csv\")\n",
    "scores3[\"Model\"] = \"Value Iteration + action based decoder\"\n",
    "\n",
    "\n",
    "all_scores = pd.concat([scores, scores2, scores3])\n",
    "sns.catplot(\n",
    "    data=all_scores[all_scores[\"Condition\"] != \"Overall\"],\n",
    "    y=\"Score\",\n",
    "    x=\"Condition\",\n",
    "    kind=\"point\",\n",
    "    hue=\"Model\",\n",
    ")\n",
    "plt.gca().set_ylim([0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ah_dtJRLCiXU"
   },
   "outputs": [],
   "source": [
    "sns.catplot(\n",
    "    data=all_scores[all_scores[\"Condition\"] == \"Overall\"],\n",
    "    y=\"Score\",\n",
    "    x=\"Model\",\n",
    "    kind=\"bar\",\n",
    ")\n",
    "plt.gca().set_ylim([0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rtMee5jxCiXU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1652455236434fd595f478f228333ade": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d1d32540b92e4e4584ac3aa628436021",
      "placeholder": "",
      "style": "IPY_MODEL_ce22fd1425e34878b5bf57a180e6b68a",
      "value": "100%"
     }
    },
    "35db648b0ccf49a898f46c7002c182ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1652455236434fd595f478f228333ade",
       "IPY_MODEL_971b821eb13d4257a7c2ae73381df11e",
       "IPY_MODEL_b44689589e2b4f1dbb45f61c49d4062f"
      ],
      "layout": "IPY_MODEL_60ad1b1ffe8c47518fb905de5a2ba43b"
     }
    },
    "3a6976f1e97e4bfa9c820ae22c022177": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "532462010a464a408a44e376dbbd6ec2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "60ad1b1ffe8c47518fb905de5a2ba43b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "971b821eb13d4257a7c2ae73381df11e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_532462010a464a408a44e376dbbd6ec2",
      "max": 1000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f15532d5a2d84f078b135130546e00f9",
      "value": 1000
     }
    },
    "a8b47418ba51421396006975690322d2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b44689589e2b4f1dbb45f61c49d4062f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a8b47418ba51421396006975690322d2",
      "placeholder": "",
      "style": "IPY_MODEL_3a6976f1e97e4bfa9c820ae22c022177",
      "value": " 1000/1000 [00:07&lt;00:00, 87.20it/s]"
     }
    },
    "ce22fd1425e34878b5bf57a180e6b68a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d1d32540b92e4e4584ac3aa628436021": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f15532d5a2d84f078b135130546e00f9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
